{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab644a-812a-4a97-b88c-9d8bbbde817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection, PolyCollection\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy.optimize import minimize\n",
    "import scipy.io as sio\n",
    "from scipy.io import readsav\n",
    "import glob\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to where data are being stored (from h3ppy fits)\n",
    "path = r\"Y:\\obs_23\\Keck_29Dec\\Kate's Final Temperatures & Densities (identical)\"\n",
    "date_fortitles = \"Dec 30, 2023\" #just used in the titles of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4091a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scamspec - contains locational information for the data\n",
    "scamspecfile = sio.readsav(r\"Y:\\obs_23\\Keck_29Dec\\spec\\scamspec_22Mar2024.sav\", verbose=False, python_dict = True)\n",
    "scamspec = scamspecfile['scamspec'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scamspec[\"SPEC_FILE\"][0] #check which data file scamspec starts on - adjust accordingly with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "startindex = 0 #change 0 to index needed if scamspec starts on a different file\n",
    "\n",
    "#longitudes\n",
    "longs_array = scamspec['AVG_LONGS']\n",
    "longs_df = pd.DataFrame(longs_array[:,startindex:]) \n",
    "\n",
    "#latitudes\n",
    "avg_lats_pc = scamspec[\"AVG_LATS_PC\"]\n",
    "lats_df = pd.DataFrame(avg_lats_pc[:,startindex:])\n",
    "\n",
    "#emission angle\n",
    "emi = pd.DataFrame(scamspec[\"AVG_EMI\"][:,startindex:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the lie of sight correction for future implementation on the densities\n",
    "LOS_corr = np.load(\"chapman_correction.npy\")\n",
    "angle = LOS_corr[0]\n",
    "corr = LOS_corr[1]\n",
    "\n",
    "\n",
    "#array of possible angles to interpolate to - in this case we have a range from 0 to 100 in steps of 0.01\n",
    "angle_highres = np.arange(0,100,0.01)\n",
    "\n",
    "#interpolating data to the size array that's easiest to work with\n",
    "coor_interp = np.interp(angle_highres, angle, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath = path + \"/latitudes\" #directory where new files with long-lat information will be stored\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "\n",
    "index = 0\n",
    "your_path = path\n",
    "files = os.listdir(your_path)\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(your_path, file)):\n",
    "        f_name, f_ext = os.path.splitext(os.path.join(your_path, file))\n",
    "        jup = pd.read_csv(os.path.join(your_path, file)) #open data file\n",
    "        density = jup[\"Densities\"] #first opening densities to apply LOS correction\n",
    "        density_err = jup[\"Density Error\"]\n",
    "        \n",
    "        corr_dens_list = []\n",
    "        corr_dens_err_list = []\n",
    "        for i in range(len(density)):\n",
    "            emi_angle = emi[index][i]\n",
    "\n",
    "            emi_index = np.abs(angle_highres - np.abs(emi_angle)).argmin() #find index of closest angle to emission angle\n",
    "            density_corr = density[len(density)-1 - i] / coor_interp[emi_index] #applying LOS correction to density\n",
    "            density_err_corr = density_err[len(density_err)-1 - i] / coor_interp[emi_index] #\" \" and density error\n",
    "            corr_dens_list.append(density_corr) \n",
    "            corr_dens_err_list.append(density_err_corr)\n",
    "        \n",
    "        corr_dens_rev = corr_dens_list[::-1] #reverse direction of list\n",
    "        corr_dens_err_rev = corr_dens_err_list[::-1] #\" \"\n",
    "           \n",
    "        print(\"Index: \" + str(index) + \" and path:\" + str(os.path.join(your_path, file)))\n",
    "        \n",
    "        juplats = lats_df[index] #define array of latitudes\n",
    "        print(Path(f_name).stem, str(np.median(juplats)))\n",
    "        juplatsrev = juplats[::-1] #reverse direction cause they're backwards\n",
    "        #print(np.median(juplats))\n",
    "        \n",
    "        juplongs = longs_df[index] #re: above\n",
    "        juplongsrev = juplongs[::-1]\n",
    "        \n",
    "               \n",
    "        jup.insert(4, \"Latitude_pc\", np.asarray(juplatsrev), True) #insert lat array into larger df\n",
    "            \n",
    "        jup.insert(4, \"Longitude_avg\", np.asarray(juplongsrev), True) #insert long array into larger df\n",
    "        \n",
    "        jup.insert(4, \"Corrected_density_error\", np.asarray(corr_dens_err_rev), True) #insert corrected density array into larger df\n",
    "        \n",
    "        jup.insert(4, \"Corrected_density\", np.asarray(corr_dens_rev), True) #insert corrected density error array into larger df\n",
    "             \n",
    "    \n",
    "        #print(jup_final)\n",
    "        #save final version of the dataframe as a csv file\n",
    "        jup.to_csv(newpath + Path(f_name).stem + \"_lats.csv\", encoding='utf-8', index=False)\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d596136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc49f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to go through files one at a time to make sure everything looks reasonable\n",
    "\n",
    "your_path = newpath #path where files were saved above\n",
    "files1 = os.listdir(your_path)\n",
    "\n",
    "#this bit is creating a list of all the file names so the function can call both the final temperatures/densities but also from the directory with fits\n",
    "name_arr = []\n",
    "count1 = 0\n",
    "for file1 in files1:\n",
    "    if os.path.isfile(os.path.join(your_path, file1)):\n",
    "        f_name, f_ext = os.path.splitext(os.path.join(your_path, file1))\n",
    "        stringname = Path(f_name).stem\n",
    "        editable = stringname.split('_')\n",
    "        partialname = str(editable[0] + \"_\" + editable[1])\n",
    "        name_arr.append(partialname)\n",
    "        count1 = count1 + 1\n",
    "print(count1)\n",
    "\n",
    "\n",
    "def plotting_func(num):\n",
    "\n",
    "    #these might need to be changed to fit your naming conventions/paths\n",
    "    jup = pd.read_csv(newpath + \"/\"+ name_arr[num] + \"_temps_lats.csv\", header = 0) #path to above files\n",
    "    jupfit = np.load(path + \"/fits/\" +  name_arr[num] +\"_fits.npy\") #path to data fits from h3ppy\n",
    "    print(name_arr[num])\n",
    "\n",
    "\n",
    "\n",
    "    plt.rcParams['axes.facecolor'] = 'white'  \n",
    "\n",
    "    #Create a x scale for plotting \n",
    "    xx      = list(range(len(jupfit[0][0])))\n",
    "    xaxis = []\n",
    "    for i in range(len(xx)):\n",
    "        xaxis.append(xx[i])\n",
    "\n",
    "    truecenters_multi = [3.41488, 3.42071, 3.45475, 3.95299] #for labeling the emission lines in the plot\n",
    "    cpos = np.arange(len(truecenters_multi)) * 28 + 15\n",
    "\n",
    "    \n",
    "#___________________________________________________#\n",
    "    #these values can be changed to view specific fits within the data file\n",
    "    slicein1 = 151\n",
    "    slicein2 = 30\n",
    "#___________________________________________________#\n",
    "\n",
    "    \n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[7,3])\n",
    "    plt.title(\"Cuthrough showing Fit and Residual\")\n",
    "    plt.plot(xaxis, (np.asarray(jupfit[0]))[slicein1], label = \"Data\", color = \"red\", linewidth = 2)\n",
    "    plt.plot(xaxis, (np.asarray(jupfit[1]))[slicein1], label = \"h3ppy Fit, temp = \"+ str(round(jup[\"Temperatures\"][slicein1])) + \"K\", color = \"tab:orange\")\n",
    "    #plt.plot(xaxis, (np.asarray(jupfit[0]) - np.asarray(jupfit[1]))[slicein1], label = \"Residual\", color = \"tab:green\")\n",
    "    ax.set(xticks = cpos)\n",
    "    ax.set_xticklabels(truecenters_multi)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[7,3])\n",
    "    plt.title(\"Cuthrough showing Fit and Residual\")\n",
    "    plt.plot(xaxis, (np.asarray(jupfit[0]))[slicein2], label = \"Data\", color = \"blue\", linewidth = 2)\n",
    "    plt.plot(xaxis, (np.asarray(jupfit[1]))[slicein2], label = \"h3ppy Fit, temp = \"+ str(round(jup[\"Temperatures\"][slicein2])) + \"K\", color = \"tab:orange\")\n",
    "    #plt.plot(xaxis, (np.asarray(jupfit[0]) - np.asarray(jupfit[1]))[slicein2], label = \"Residual\", color = \"tab:green\")\n",
    "    ax.set(xticks = cpos)\n",
    "    ax.set_xticklabels(truecenters_multi)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    maxerror = []\n",
    "    for i in range(len(jup[\"Temperatures\"])):\n",
    "        if jup[\"Temperatures\"][i] == -666 or jup[\"Temperature Error\"][i] == -666 or np.abs(jup[\"Latitude_pc\"][i]) > 90:\n",
    "            maxerror.append(np.nan)\n",
    "            if jup[\"Temperatures\"][i] == -666 and np.abs(jup[\"Latitude_pc\"][i]) < 90:\n",
    "                print(\"666 Index: \", i)\n",
    "        else:\n",
    "            maxerrorvalue = jup[\"Temperatures\"][i] + jup[\"Temperature Error\"][i]\n",
    "            maxerror.append(maxerrorvalue)\n",
    "    maxerror_arr = np.asarray(maxerror)\n",
    "\n",
    "    minerror = []\n",
    "    for i in range(len(jup[\"Temperatures\"])):\n",
    "        if jup[\"Temperatures\"][i] == -666 or jup[\"Temperature Error\"][i] == -666 or np.abs(jup[\"Latitude_pc\"][i]) > 90:\n",
    "            minerror.append(np.nan)\n",
    "        else:\n",
    "            minerrorvalue = jup[\"Temperatures\"][i] - jup[\"Temperature Error\"][i]\n",
    "            minerror.append(minerrorvalue)\n",
    "    minerror_arr = np.asarray(minerror)\n",
    "\n",
    "    plt.rcParams['axes.facecolor'] = 'white'  \n",
    "\n",
    "    plt.subplots(figsize=[16, 6])\n",
    "\n",
    "\n",
    "\n",
    "    plt.fill_between(jup[\"Latitude_pc\"], minerror_arr, maxerror_arr, color = \"wheat\", alpha = 1)\n",
    "    plt.scatter(jup[\"Latitude_pc\"], jup[\"Temperatures\"], color = \"brown\")\n",
    "    plt.axvline(x = jup[\"Latitude_pc\"][slicein1], color = \"red\")\n",
    "    plt.axvline(x = jup[\"Latitude_pc\"][slicein2], color = \"blue\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plt.axvline(x = -23, color = \"r\", label = \"Approximate GRS Boundaries\")\n",
    "    #plt.axvline(x = -11, color = \"r\")\n",
    "\n",
    "    plt.title(\"CML \" + str(round(np.median(jup[\"Longitude_avg\"]),2)) + \" (\"+ date_fortitles + \"); file: \" + name_arr[num])\n",
    "    plt.xlabel(\"Latitude$_{PC}$ (°)\")\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(\"Temperature $H_3^+$ (K)\")\n",
    "    #plt.grid(visible = True)\n",
    "\n",
    "    if \"S\" in name_arr[num] or 's' in name_arr[num]:\n",
    "        plt.xlim(-90,10)\n",
    "        #plt.legend(loc = \"lower left\")\n",
    "        #print(\"South\")\n",
    "    elif \"N\" in name_arr[num] or \"n\" in name_arr[num]:\n",
    "        plt.xlim(-10,90)\n",
    "        #plt.legend(loc = \"lower right\")\n",
    "        #print(\"North\")\n",
    "\n",
    "    plt.ylim(500, 2000)\n",
    "\n",
    "    #plt.savefig('C:/Users/rober/Pictures/Research Figures/epsc 2023 figures/GRS temp fit.png')\n",
    "    #plt.savefig('C:/Users/kater00/Documents/Research Figures/GRS temp fit.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fe5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with whatever position you want, I'd reccomend count = 0\n",
    "#then comment out count and rerun the cell to progress through all of the data files\n",
    "#if there's a file you want to look at multiple fits within (if you have an extreme outlier):\n",
    "        #1: you can change the indices for the fits in the above function\n",
    "        #2: you can set the count to the number showing (because count is printed each time at the top of the graphs)\n",
    "        #3: if you leave the count uncommented with the value of the file you want to look at, you can rerun the cell as many times as you need\n",
    "count = 0\n",
    "\n",
    "print(\"Count:\", count)\n",
    "plotting_func(count)\n",
    "count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c51ea-9ae7-47ff-b624-bd938d3e4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once you're happy with all of the fits you can move onto plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4417e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all of the data into big lists\n",
    "\n",
    "lats = []\n",
    "longs = []\n",
    "temps = []\n",
    "temperr = []\n",
    "dens = []\n",
    "denerr = []\n",
    "\n",
    "lats_big = []\n",
    "longs_big = []\n",
    "\n",
    "index = 0\n",
    "your_path = newpath #path from above where files were saved\n",
    "files = os.listdir(your_path)\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(your_path, file)):\n",
    "        jup = pd.read_csv(os.path.join(your_path, file)) #open data file\n",
    "        jup_lats = jup[\"Latitude_pc\"]\n",
    "        jup_longs = jup[\"Longitude_avg\"]\n",
    "        jup_temps = jup[\"Temperatures\"]\n",
    "        jup_temperr = jup[\"Temperature Error\"]\n",
    "        jup_dens = jup[\"Densities\"]\n",
    "        jup_denerr = jup[\"Density Error\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(jup_temps)):\n",
    "            lats_big.append(jup_lats[i]) #these used in the next cell for intensities\n",
    "            longs_big.append(jup_longs[i])\n",
    "\n",
    "            #skips any \"obviously wrong data\" including the dummy variables put in during h3ppy fits and off-planet values from the lat-long mapping\n",
    "            if jup_temps[i] == -666 or jup_temperr[i] == 666 or \\\n",
    "               jup_temps[i] == np.nan or jup_temperr[i] == np.nan or \\\n",
    "               jup_dens[i]  == -666 or jup_denerr[i] == 666 or \\\n",
    "               jup_dens[i]  == np.nan or jup_denerr[i] == np.nan or \\\n",
    "               np.abs(jup_lats[i]) > 90 or np.abs(jup_longs[i]) > 360:\n",
    "                continue\n",
    "            else:\n",
    "                lats.append(jup_lats[i])\n",
    "                longs.append(jup_longs[i])\n",
    "                temps.append(jup_temps[i])\n",
    "                temperr.append(jup_temperr[i])\n",
    "                dens.append(jup_dens[i])\n",
    "                denerr.append(jup_denerr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is specifically for mapping intensities \n",
    "#need all of the lats/longs from before because the fits (where the intensity value comes from) haven't been cropped\n",
    "peak_value = []\n",
    "your_path = \"Y:/obs_23/Keck_29Dec/Kate's Final Temperatures & Densities (identical)/fits\" #or wherever you're keeping your fits from the h3ppy routines\n",
    "files = os.listdir(your_path)\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(your_path, file)):\n",
    "        jup = np.load(os.path.join(your_path, file))\n",
    "        \n",
    "        data = jup[0]\n",
    "        for i in range(len(data)):\n",
    "            value = data[i][-15]\n",
    "            peak_value.append(value)\n",
    "            \n",
    "peak_value_short = []\n",
    "longs_big_short = []\n",
    "lats_big_short = []\n",
    "\n",
    "for i in range(len(peak_value)):\n",
    "    if np.abs(lats_big[i]) > 90 or np.abs(longs_big[i]) > 360: #now the bad values from above can be dropped\n",
    "        continue\n",
    "    else:\n",
    "        #print(lats_big[i])\n",
    "        peak_value_short.append(peak_value[i])\n",
    "        lats_big_short.append(lats_big[i])\n",
    "        longs_big_short.append(longs_big[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=[7, 10])\n",
    "\n",
    "plt.rcParams.update({'lines.markersize': 5})\n",
    "plt.rcParams['axes.facecolor'] = 'darkgrey'\n",
    "\n",
    "\n",
    "#update colorbar bounds to improve contrast if necessary\n",
    "vmin = 1e-3\n",
    "vmax = 3e-2\n",
    "\n",
    "markersize = np.full(\n",
    "  shape=len(longs_big_short),\n",
    "  fill_value=40,\n",
    "  dtype=int\n",
    ")\n",
    "\n",
    "colors_cube = plt.get_cmap('gist_stern')(np.linspace(0, 1, 7))\n",
    "cmap_segmented = LinearSegmentedColormap.from_list('cubehelix_segmented', colors_cube, N = 11)\n",
    "\n",
    "scatter = plt.scatter(longs_big_short, lats_big_short, s = markersize, c = peak_value_short, cmap = cmap_segmented, \n",
    "                       vmin = vmin, vmax = vmax, linewidth = 0, marker = \"*\")\n",
    "cbar = plt.colorbar(scatter, shrink = 0.9, extend = \"both\")\n",
    "cbar.set_label(r\"Intensity ($W/m^2/\\mu m/sr$)\")\n",
    "\n",
    "\n",
    "plt.xlim(60,217) #update bounds for longs\n",
    "plt.gca().invert_xaxis()\n",
    "plt.minorticks_on()\n",
    "\n",
    "\n",
    "\n",
    "plt.title(date_fortitles, color = \"purple\")\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531df42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the variable names in case you accidently rerun something above \n",
    "#(also cause I apparently changed my names somehwere along the way and this is the solution I've been living with)\n",
    "lats_arr = lats\n",
    "longs_arr = longs\n",
    "temps_arr = temps\n",
    "temperr_arr = temperr\n",
    "dens_arr = dens\n",
    "denerr_arr = denerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fa3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for creating data bins for plotting\n",
    "#all this does is create literal boxes in lat and long - the loops look for lat-long points of data which fall inside a region\n",
    "#if there's a point, it gets added to a list; once all the data have been searched, the loop takes a bootstrap median of the temp and density\n",
    "#then the root mean square of the uncertainties for everything in the bin as well as the standard deviation\n",
    "#those 3 values then get appended to their respctive lists, and the loop makes the next bin and continues the search\n",
    "\n",
    "step_lat = 3 #can update bins to whatever size you want - this was just what we ended up using\n",
    "step_long = 6\n",
    "bounds_list_longs = list(range(50, 360 - step_long, step_long))\n",
    "bounds_list_lats = list(range(-90, 90 - step_lat, step_lat))\n",
    "\n",
    "long_up = []\n",
    "long_down = []\n",
    "lat_small = []\n",
    "lat_large = []\n",
    "\n",
    "temp_lats = []\n",
    "terr_lats = []\n",
    "tstd_lats = []\n",
    "dens_lats = []\n",
    "derr_lats = []\n",
    "dstd_lats = []\n",
    "\n",
    "# Function to generate bootstrapped samples and compute medians\n",
    "def bootstrap_median(values, errors, n_bootstraps = 1000):\n",
    "    medians = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        # Generate a sample considering the errors\n",
    "        sample = np.random.normal(values, errors)\n",
    "        medians.append(np.median(sample))\n",
    "    return np.array(medians)\n",
    "\n",
    "for bound_long in bounds_list_longs:\n",
    "    for bound_lat in bounds_list_lats:\n",
    "        temp_list = []\n",
    "        dens_list = []\n",
    "        temp_err_list = []\n",
    "        dens_err_list = []\n",
    "\n",
    "        for i in range(len(lats)):\n",
    "            if lats[i] > bound_lat and lats[i] < bound_lat + step_lat \\\n",
    "                and longs[i] > bound_long and longs[i] < bound_long + step_long:\n",
    "                \n",
    "                temp_list.append(temps_arr[i])\n",
    "                temp_err_list.append(temperr_arr[i])\n",
    "                dens_list.append(dens_arr[i])\n",
    "                dens_err_list.append(denerr_arr[i])\n",
    "                \n",
    "        if len(temp_list)>0:\n",
    "            temp_median = np.median(bootstrap_median(temp_list, temp_err_list)) #median value from bootstrap\n",
    "            dens_median = np.median(bootstrap_median(dens_list, dens_err_list)) # \" \"        \n",
    "            temp_err = np.sqrt(sum(np.asarray(temp_err_list)**2)/len(temp_err_list)) #RMS error\n",
    "            dens_err = np.sqrt(sum(np.asarray(dens_err_list)**2)/len(dens_err_list)) #\" \"\n",
    "            temp_std = np.std(temp_list) #standard deviation\n",
    "            dens_std = np.std(dens_list) #\"  \"\n",
    "                     \n",
    "            \n",
    "            temp_lats.append(temp_median)\n",
    "            dens_lats.append(dens_median)\n",
    "            terr_lats.append(temp_err)\n",
    "            derr_lats.append(dens_err)\n",
    "            tstd_lats.append(temp_std)\n",
    "            dstd_lats.append(dens_std)\n",
    "        elif len(temp_list) == 0: #if no values fall within a given bin, that bin is filled with nan\n",
    "            temp_lats.append(np.nan)\n",
    "            dens_lats.append(np.nan)\n",
    "            tstd_lats.append(np.nan)\n",
    "            dstd_lats.append(np.nan)\n",
    "            \n",
    "\n",
    "        #saving the \"four corners\" for every bin created\n",
    "        long_down.append(bound_long)\n",
    "        long_up.append(bound_long + step_long)\n",
    "        lat_small.append(bound_lat)\n",
    "        lat_large.append(bound_lat + step_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in dark ribbon and auroral coordinates\n",
    "darkribbon = pd.read_csv(r\"Y:\\obs_22\\H3+ Dark Ribbon Coordinates Stallard et al.csv\", header = None)\n",
    "outer = pd.read_csv(r\"Y:/tools/auroral ovals/outer ovals.csv\", dtype=np.float64)\n",
    "\n",
    "\n",
    "#if you want to plot the location of the GRS\n",
    "# Define the equation of an ellipse\n",
    "def ellipse_eq(params, x, y):\n",
    "    x0, y0, a, b, angle = params\n",
    "    theta = np.deg2rad(angle)\n",
    "    x_rot = (x - x0) * np.cos(theta) - (y - y0) * np.sin(theta)\n",
    "    y_rot = (x - x0) * np.sin(theta) + (y - y0) * np.cos(theta)\n",
    "    return np.sum(((x_rot / a) ** 2 + (y_rot / b) ** 2 - 1) ** 2)\n",
    "\n",
    "\n",
    "GRSwidth = 14.48 #width in longitude, degrees\n",
    "\n",
    "#create line to map GRS - GRS drifts in longitude, create new ones\n",
    "# Initial guess for the parameters\n",
    "#this guess is [center longitude, center latitude, and then some stuff that I wouldn't change]\n",
    "initial_params = [101.8425, -17, 10, 10, 0]  # all you really need to change is the first number (center longitude, degrees W)\n",
    "\n",
    "\n",
    "data_points = np.array([\n",
    "    [initial_params[0], -23],\n",
    "    [initial_params[0], -11],\n",
    "    [initial_params[0] - GRSwidth/2, initial_params[1]],\n",
    "    [initial_params[0] + GRSwidth/2, initial_params[1]]\n",
    "])\n",
    "\n",
    "# Fit the ellipse to the data points\n",
    "result = minimize(ellipse_eq, initial_params, args=(data_points[:, 0], data_points[:, 1]))\n",
    "\n",
    "# Extract the fitted parameters\n",
    "x0, y0, a, b, angle = result.x\n",
    "\n",
    "# Create points for the ellipse\n",
    "theta_GRS = np.linspace(0, 2 * np.pi, 100)\n",
    "x_fit_GRS = x0 + a * np.cos(theta_GRS)\n",
    "y_fit_GRS = y0 + b * np.sin(theta_GRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot map as individual sactter points:\n",
    "#(points are center of pixel along slit and not accounting for width of slit or seeing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=[7, 10]) #change figure size, [width, height]\n",
    "\n",
    "plt.rcParams.update({'lines.markersize': 5})\n",
    "plt.rcParams['axes.facecolor'] = 'gray'\n",
    "\n",
    "\n",
    "#bounds for temperatures - change to improve contrast\n",
    "vmin = 650\n",
    "vmax = 1350\n",
    "\n",
    "#you can always make your own colormap too if you want - I use this site:\n",
    "#https://gka.github.io/palettes/#/9|s|00429d,96ffea,ffffe0|ffffe0,ff005e,93003a|1|1\n",
    "\n",
    "temp_cmap = ListedColormap(['#1d2949', '#2c3361', '#3e3d76', '#544786', '#6a5291', '#815e97', '#966b99', \\\n",
    "                            '#aa7a97', '#bc8993', '#cd9a8c', '#dbac84', '#e8be7b', '#f4d170', '#ffe463'])\n",
    "\n",
    "#data\n",
    "markersize = np.full(\n",
    "  shape=len(longs_arr),\n",
    "  fill_value=40, #can make markers bigger or smaller with this\n",
    "  dtype=int\n",
    ")\n",
    "\n",
    "scatter = plt.scatter(longs_arr, lats_arr, s = markersize, c = temps_arr, cmap = temp_cmap, \n",
    "                       vmin = vmin, vmax = vmax, linewidth = 0, marker = \"*\")\n",
    "\n",
    "\n",
    "#colorbar info\n",
    "cbar = plt.colorbar(scatter, shrink = 0.9, extend = \"max\")\n",
    "cbar.set_label(\"Column-Integrated Temperature (K)\")\n",
    "\n",
    "#locational indicators\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\") #the southern oval plots weird wihtout splitting - just go with it\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "plt.plot(x_fit_GRS, y_fit_GRS, label='GRS: ' + date_fortitles, color='white', alpha = 0.7)\n",
    "\n",
    "\n",
    "plt.xlim(60,217) #change for longitude bounds\n",
    "\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.minorticks_on()\n",
    "plt.title(date_fortitles, color = \"purple\")\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d45133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot using bins from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f17bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=[7, 10])\n",
    "\n",
    "\n",
    "polygons = []\n",
    "\n",
    "cmap = temp_cmap\n",
    "norm = matplotlib.colors.Normalize(650, 1350) #change colormap bounds here\n",
    "\n",
    "for i in range(len(long_down)):\n",
    "    verts = [\n",
    "        (long_down[i], lat_small[i]),\n",
    "        (long_down[i], lat_large[i]),\n",
    "        (long_up[i], lat_large[i]),\n",
    "        (long_up[i], lat_small[i])\n",
    "            ]\n",
    "    polygons.append(verts)\n",
    "\n",
    "collection = PolyCollection(polygons, cmap=cmap, norm=norm, edgecolors='None') #calls colormap from above\n",
    "\n",
    "collection.set_array(temp_lats)\n",
    "\n",
    "ax.add_collection(collection)\n",
    "ax.autoscale_view()\n",
    "plt.colorbar(collection, ax=ax, label='Column-Integrated Temperature (K)', extend = \"max\")\n",
    "\n",
    "#locational indicators\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\") #the southern oval plots weird wihtout splitting - just go with it\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "plt.plot(x_fit_GRS, y_fit_GRS, label='GRS: ' + date_fortitles, color='white', alpha = 0.7)\n",
    "\n",
    "\n",
    "plt.xlim(60,217)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.minorticks_on()\n",
    "plt.title(date_fortitles, color = \"purple\")\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366643e-8f8b-4c0e-9a8f-b28b28410043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now onto densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=[6, 10])\n",
    "\n",
    "plt.rcParams.update({'lines.markersize': 5})\n",
    "plt.rcParams['axes.facecolor'] = 'gray'\n",
    "\n",
    "\n",
    "vmin = 1e15\n",
    "vmax = 5e15\n",
    "\n",
    "dens_cmap = ListedColormap(['#692038', '#8c354d', '#a1575a', '#ab7d62', '#b3a26b', '#bec57b', '#d5e497', '#fdffc1'])\n",
    "\n",
    "\n",
    "markersize = np.full(\n",
    "  shape=len(longs_arr),\n",
    "  fill_value=40,\n",
    "  dtype=int\n",
    ")\n",
    "\n",
    "scatter = plt.scatter(longs_arr, lats_arr, s = markersize, c = dens_arr, cmap = dens_cmap, \n",
    "                       vmin = vmin, vmax = vmax, linewidth = 0, marker = \"*\")\n",
    "\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(scatter, extend = \"both\", shrink = 0.9)\n",
    "cbar.set_label(\"Column-Integrated Density ($m^{-2}$)\")\n",
    "\n",
    "#including locational indicators (GRS, GCS, auroral ovals, h3+ dark ribbon)\n",
    "plt.plot(x_fit_GRS, y_fit_GRS, label='GRS Dec 29 2023', color='white', alpha = 0.7)\n",
    "plt.scatter(darkribbon[1], darkribbon[0], label = \"$H_3^+$ Dark Ribbon\", color = \"white\", marker = \"x\")\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "\n",
    "plt.xlim(60,217)\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.title('$H_3^+$ Densities: ' +  date_fortitles)\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('Latitude$_{PC}$')\n",
    "plt.legend(bbox_to_anchor=(0.5, -0.1), ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=[7, 10])\n",
    "\n",
    "\n",
    "polygons = []\n",
    "\n",
    "cmap = dens_cmap\n",
    "norm = matplotlib.colors.Normalize(1e15, 5e15) #change colormap bounds here\n",
    "\n",
    "for i in range(len(long_down)):\n",
    "    verts = [\n",
    "        (long_down[i], lat_small[i]),\n",
    "        (long_down[i], lat_large[i]),\n",
    "        (long_up[i], lat_large[i]),\n",
    "        (long_up[i], lat_small[i])\n",
    "            ]\n",
    "    polygons.append(verts)\n",
    "\n",
    "collection = PolyCollection(polygons, cmap=cmap, norm=norm, edgecolors='None') #calls colormap from above\n",
    "\n",
    "collection.set_array(dens_lats)\n",
    "\n",
    "ax.add_collection(collection)\n",
    "ax.autoscale_view()\n",
    "plt.colorbar(collection, ax=ax, label='Column-Integrated Density ($m^{-2}$)', extend = \"both\")\n",
    "\n",
    "#locational indicators\n",
    "plt.plot(x_fit_GRS, y_fit_GRS, label='GRS Dec 29 2023', color='white', alpha = 0.7)\n",
    "plt.scatter(darkribbon[1], darkribbon[0], label = \"$H_3^+$ Dark Ribbon\", color = \"white\", marker = \"x\")\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "\n",
    "plt.xlim(60,217)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.minorticks_on()\n",
    "plt.title(date_fortitles, color = \"purple\")\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c89acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp error, I'll leave making the binned plots as an exercise to the useer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b78790",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=[6, 10])\n",
    "\n",
    "plt.rcParams.update({'lines.markersize': 5})\n",
    "plt.rcParams['axes.facecolor'] = 'gray'\n",
    "\n",
    "\n",
    "vmin = 0\n",
    "vmax = 8\n",
    "\n",
    "markersize = np.full(\n",
    "  shape=len(longs_arr),\n",
    "  fill_value=40,\n",
    "  dtype=int\n",
    ")\n",
    "\n",
    "\n",
    "temp_cmap = ListedColormap(['#283d80', '#64537b', '#8b6d7a', '#aa8981',\\\n",
    "                            '#c5a88e', '#ddc8a0', '#f4eab4', '#fffbbf'])\n",
    "\n",
    "scatter = plt.scatter(longs_arr, lats_arr, s = markersize, c = (np.asarray(temperr_arr)/np.asarray(temps_arr))*100, \\\n",
    "                      cmap = \"bone\", vmin = vmin, vmax = vmax, linewidth = 0, marker = \"*\")\n",
    "cbar = plt.colorbar(scatter, shrink = 0.9, extend = \"max\")\n",
    "cbar.set_label(\"Root Mean Square Temperature Error (%)\")\n",
    "\n",
    "#including locational indicators (GRS, GCS, auroral ovals, h3+ dark ribbon)\n",
    "#plt.plot(x_fit_GRS, y_fit_GRS, label='GRS Dec 29 2023', color='white', alpha = 0.7)\n",
    "#plt.scatter(darkribbon[1], darkribbon[0], label = \"$H_3^+$ Dark Ribbon\", color = \"white\", marker = \"x\")\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim(60,217)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "#plt.title('$H_3^+$ Temperatures\\nDec 15, 2022')\n",
    "plt.title(date_fortitles)\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "#plt.legend(bbox_to_anchor=(0.5, -0.1), ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c94bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#density error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=[7, 10])\n",
    "\n",
    "plt.rcParams.update({'lines.markersize': 5})\n",
    "plt.rcParams['axes.facecolor'] = 'gray'\n",
    "\n",
    "\n",
    "vmin = 0\n",
    "vmax = 30\n",
    "\n",
    "markersize = np.full(\n",
    "  shape=len(longs_arr),\n",
    "  fill_value=40,\n",
    "  dtype=int\n",
    ")\n",
    "\n",
    "\n",
    "temp_cmap = ListedColormap(['#283d80', '#64537b', '#8b6d7a', '#aa8981',\\\n",
    "                            '#c5a88e', '#ddc8a0', '#f4eab4', '#fffbbf'])\n",
    "\n",
    "scatter = plt.scatter(longs_arr, lats_arr, s = markersize, c = (np.asarray(denerr_arr)/np.asarray(dens_arr))*100, \\\n",
    "                      cmap = \"pink\", vmin = vmin, vmax = vmax, linewidth = 0, marker = \"*\")\n",
    "cbar = plt.colorbar(scatter, shrink = 0.9, extend = \"max\")\n",
    "cbar.set_label(\"Root Mean Square Density Error (%)\")\n",
    "\n",
    "#including locational indicators (GRS, GCS, auroral ovals, h3+ dark ribbon)\n",
    "#plt.plot(x_fit_GRS, y_fit_GRS, label='GRS Dec 29 2023', color='white', alpha = 0.7)\n",
    "#plt.scatter(darkribbon[1], darkribbon[0], label = \"$H_3^+$ Dark Ribbon\", color = \"white\", marker = \"x\")\n",
    "plt.plot(outer[\"Lon_N\"], outer[\"Lat_N\"], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][0:2889], outer[\"Lat_S\"][0:2889], color = \"black\")\n",
    "plt.plot(outer[\"Lon_S\"][2889:], outer[\"Lat_S\"][2889:], color = \"black\")\n",
    "\n",
    "plt.xlim(60,217)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.title(date_fortitles)\n",
    "plt.xlabel(\"CML (°W)\")\n",
    "plt.ylabel('$Latitude_{PC}$')\n",
    "#plt.legend(bbox_to_anchor=(0.5, -0.1), ncol = 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
